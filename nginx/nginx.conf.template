server {
    listen 80; # Listen on port 80
    location / {
        # Serve static files from the specified directory
        root /usr/share/nginx/html;
        # Default file to serve
        index index.html index.htm;
    }
    # Location block for forwarding API requests to the vLLM server
    location /llm_api/ {
        # --- API Key Check ---
        # Check if the incoming request has an 'Api-Key' HTTP Header
        # Bearer means owner, tell server the following in api-key
        set $expected_auth "Bearer ${LLM_API_KEY}";

        if ($http_authorization != $expected_auth) {
            return 401 'Unauthorized';
        } 
        # --- End of Check ---

        # (If the key is correct, Nginx continues with the settings below)

        # Forward the request to the GPU server, rewriting the path.
        # Example: /llm_api/chat -> /v1/chat
        proxy_pass http://${GPU_SERVER_IP}:8000/v1/;

        # Pass the original 'Host' header from the client to the upstream server
        proxy_set_header Host $host;

        # Pass the client's real IP address to the upstream server
        proxy_set_header X-Real-IP $remote_addr;

        # Pass the chain of IPs the request has gone through (standard proxy header)
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

        # Pass the original protocol (http or https) used by the client
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
